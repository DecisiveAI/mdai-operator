apiVersion: hub.mydecisive.ai/v1
kind: MdaiHub
metadata:
  labels:
    app.kubernetes.io/name: mdai-operator
    app.kubernetes.io/managed-by: kustomize
  name: mdaihub-second
  namespace: mdai
spec:
  variables:
    - key: service_list
      dataType: set
      serializeAs:
        - name: "SERVICE_LIST"
          transformers:
            - type: join
              join:
                delimiter: "|"
    - key: highRiskStates
      dataType: set
      serializeAs:
        - name: "HIGH_RISK_STATES"
          transformers:
            - type: join
              join:
                delimiter: "|"
    - key: filter
      dataType: string
      serializeAs:
        - name: "FILTER"
    - key: riskLevel
      dataType: string
      serializeAs:
        - name: "RISK_LEVEL"
    - key: severity_number
      dataType: int
      serializeAs:
        - name: "SEVERITY_NUMBER"
    - key: any_service_alerted
      dataType: boolean
      serializeAs:
        - name: "SERVICE_ALERTED"
    - key: attribute_map
      dataType: map
      serializeAs:
        - name: "ATTRIBUTES"
    - key: severity_filters_by_level
      dataType: map
      serializeAs:
        - name: "SEVERITY_FILTERS_BY_LEVEL"
    - key: my_priority_list
      type: meta
      dataType: metaPriorityList
      variableRefs:
        - default
        - service_list
      serializeAs:
        - name: "SERVICE_PRIORITY"
          transformers:
            - type: join
              join:
                delimiter: "|"
    - key: my_hash_set
      type: meta
      dataType: metaHashSet
      variableRefs:
        - severity_number
        - severity_filters_by_level
      serializeAs:
        - name: "SERVICE_HASH_SET"

  prometheusAlerts:
    - name: logBytesOutTooHighBySvc
      expr: 'increase(mdai_log_bytes_sent_total[1h]) > 100*1024*1024'
      severity: warning
      for: 5m
      keep_firing_for: 10m
    - name: anomalous_error_rate
      expr: 'sum(increase(error_logs_by_service_total[5m])) by (mdai_service) > 2 * sum(avg_over_time(increase(error_logs_by_service_total[5m])[1h:])) by (mdai_service) and (sum by (mdai_service) (error_logs_by_service_total offset 1h))'
      severity: warning
      for: 3m
      keep_firing_for: 3m

  rules:
    - name: HandleAddNoisyServiceToSet
      when:
        alertName: logBytesOutTooHighBySvc
        status: firing
      then:
        - addToSet:
            set: service_list
            value: ${trigger:payload.labels.service_name}
        - addToMap:
            map: severity_filters_by_level
            key: ${trigger:payload.labels.service_name}
            value: high
    - name: HandleRemoveNoisyServiceFromSet
      when:
        alertName: logBytesOutTooHighBySvc
        status: resolved
      then:
        - removeFromSet:
            set: service_list
            value: ${trigger:payload.labels.service_name}
        - removeFromMap:
            map: severity_filters_by_level
            key: ${trigger:payload.labels.service_name}
    - name: TrackCriticalRiskLevel
      when:
        variableUpdated: riskLevel
        updateType: set
      then:
        - addToSet:
            set: highRiskStates
            value: ${trigger:payload.labels.service_name}
        - setVariable:
            scalar: severity_number
            value: "3"

    - name: anomalous_error_rate
      when:
        alertName: anomalous_error_rate
        status: firing
      then:
        - callWebhook:
            url:
              valueFrom:
                secretKeyRef: { name: slack-webhook-secret, key: url }
            templateRef: slackAlertTemplate
            templateValues:
              labels_val_ref_primary: mdai_service
              message: Service was >2x expected error rate for five minutes compared to the last hour!
              link_text: See alert in Prometheus
              link_url: http://localhost:9090/alerts
        # Notify pagerduty
        - callWebhook:
            url:
              value: https://events.pagerduty.com/v2/enqueue
            method: POST
            templateRef: jsonTemplate
            payloadTemplate:
              valueFrom:
                configMapKeyRef: { name: webhook-templates-pagerduty, key: pagerduty.json }
            templateValuesFrom:
              routing_key:
                secretKeyRef: { name: pagerduty, key: routing_key }
            headers:
              Content-Type: application/json
            timeout: 10s
        # GitHub release workflow dispatch
        - callWebhook:
            url: { value: https://api.github.com/repos/OWNER/REPO/actions/workflows/deploy.yml/dispatches }
            method: POST
            templateRef: jsonTemplate
            payloadTemplate: # could be used from config map, using `value` for testing purpose
              value: |
                {
                  "ref":      "${template:ref:-main}",
                  "inputs": { "env": "${template:env:-prod}", "build_id": "${trigger:id}" }
            templateValues:
              env: uat # should override default
            headersFrom:
              Authorization:
                secretKeyRef: { name: github-token, key: authorization }   # "Bearer ghp_xxx"
            headers:
              Accept: application/vnd.github+json
              X-GitHub-Api-Version: "2022-11-28"
              Content-Type: application/json
        # ServiceNow incident creation
        - callWebhook:
            url: { value: https://acme.service-now.com/api/now/table/incident }
            method: POST
            templateRef: jsonTemplate
            payloadTemplate:
              valueFrom:
                configMapKeyRef: { name: webhook-templates, key: servicenow-incident.json }
            headersFrom:
              Authorization:
                secretKeyRef: { name: servicenow-oauth, key: authorization }  # "Bearer eyJ..."
            headers:
              Accept: application/json
              Content-Type: application/json